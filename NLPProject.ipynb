{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPProject.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOATLmEvX+Jo91QBYLQIumW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GajeraKishan/NaturalLanguageInference/blob/master/NLPProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOYDh1NAE2YV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80822fa2-70a9-46b0-aa22-c90cf9695362"
      },
      "source": [
        "pip install mecab-python3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (0.996.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIaU0EYlE-PX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "f93e0bf5-e40f-4313-d52f-b1182d405fa9"
      },
      "source": [
        "!pip install fairseq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 24.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 23.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 10.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 122kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143kB 10.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 163kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 174kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 184kB 10.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 194kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 204kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 215kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 225kB 10.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 235kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 245kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 256kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 266kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 286kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 296kB 10.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/58/5c6cc352ea6271125325950715cf8b59b77abe5e93cf29f6e60b491a31d9/sacrebleu-1.4.6-py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.38.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/64/03/9abfb3374d67838daf24f1a388528714bec1debb1d13749f0abd7fb07cfb/portalocker-1.6.0-py2.py3-none-any.whl\n",
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1MB 203kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2015421 sha256=b1f3fcbaab5c5270dd90f033b6152e3ef50d61b6b0093bfb22c763fe282f4473\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, mecab-python3, sacrebleu, fairseq\n",
            "Successfully installed fairseq-0.9.0 mecab-python3-0.996.5 portalocker-1.6.0 sacrebleu-1.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R77YAYFoFD1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "19947db7-c96c-4389-a8e9-d5e98fee2e99"
      },
      "source": [
        "!gdown 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n",
            "To: /content/encoder.json\n",
            "1.04MB [00:00, 1.08MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4bvYY4IFE9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ebcae1e4-a8ee-4145-ef65-8f5f37800645"
      },
      "source": [
        "!gdown 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n",
            "To: /content/vocab.bpe\n",
            "456kB [00:00, 638kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qjo6-jZFRLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4e7e2450-2ea9-4c4d-a3c3-725b58dfe93b"
      },
      "source": [
        "!bash python multiprocessing_bpe_encoder.py --encoder-json encoder.json --vocab-bpe vocab.bpe --inputs \"sentences_train.txt\" --outputs \"train.input0.bpe\" --workers 1 --keep-empty"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "processed 40000 lines\n",
            "processed 50000 lines\n",
            "processed 60000 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-RhQpasFfA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0210ac2-b4d1-4c08-dacf-a0e9a6595568"
      },
      "source": [
        "!bash python multiprocessing_bpe_encoder.py --encoder-json encoder.json --vocab-bpe vocab.bpe --inputs \"sentences_val.txt\" --outputs \"dev.input0.bpe\" --workers 1 --keep-empty"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 10000 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4qnsPrFmaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "645e796a-6b94-4589-ce15-d8d2b4020e81"
      },
      "source": [
        "!gdown 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
            "To: /content/dict.txt\n",
            "603kB [00:00, 788kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyU-IuMXFxQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1abf4867-6b03-4dc7-83fc-68434774422f"
      },
      "source": [
        "!fairseq-preprocess --only-source --trainpref \"train.input0.bpe\" --validpref \"dev.input0.bpe\" --destdir \"train-bin/input0\" --workers 60 --srcdict dict.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='train-bin/input0', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, seed=1, source_lang=None, srcdict='dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='train.input0.bpe', user_dir=None, validpref='dev.input0.bpe', workers=60)\n",
            "| [None] Dictionary: 50263 types\n",
            "| [None] train.input0.bpe: 60000 sents, 7734940 tokens, 0.0% replaced by <unk>\n",
            "| [None] Dictionary: 50263 types\n",
            "| [None] dev.input0.bpe: 10000 sents, 1192525 tokens, 0.0% replaced by <unk>\n",
            "| Wrote preprocessed data to train-bin/input0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XZytORLFyTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "910037f1-326b-4689-b2b6-9e74f44be405"
      },
      "source": [
        "!fairseq-preprocess --only-source --trainpref \"labels_train.txt\" --validpref \"labels_val.txt\" --destdir \"train-bin/label\" --workers 60"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='train-bin/label', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, seed=1, source_lang=None, srcdict=None, target_lang=None, task='translation', tensorboard_logdir='', testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='labels_train.txt', user_dir=None, validpref='labels_val.txt', workers=60)\n",
            "| [None] Dictionary: 7 types\n",
            "| [None] labels_train.txt: 60000 sents, 120000 tokens, 0.0% replaced by <unk>\n",
            "| [None] Dictionary: 7 types\n",
            "| [None] labels_val.txt: 10000 sents, 20000 tokens, 0.0% replaced by <unk>\n",
            "| Wrote preprocessed data to train-bin/label\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED2uTfVeF363",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "596e1a00-56e1-4c78-894d-7c79e860a421"
      },
      "source": [
        "!bash  python train.py train-bin/ \\\n",
        "    --restore-file model.pt \\\n",
        "    --max-positions 512 \\\n",
        "    --max-sentences 2 \\\n",
        "    --max-tokens 4400 \\\n",
        "    --task sentence_prediction \\\n",
        "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "    --required-batch-size-multiple 1 \\\n",
        "    --init-token 0 --separator-token 2 \\\n",
        "    --arch roberta_large \\\n",
        "    --criterion sentence_prediction \\\n",
        "    --num-classes 2 \\\n",
        "    --dropout 0.1 --attention-dropout 0.1 \\\n",
        "    --weight-decay 0.1 --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-04 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --lr-scheduler polynomial_decay --lr 0.00001 --total-num-update 10000 --warmup-updates 50 \\\n",
        "    --fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 \\\n",
        "    --max-epoch 5 \\\n",
        "    --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \\\n",
        "    --truncate-sequence \\\n",
        "    --find-unused-parameters \\\n",
        "    --update-freq 16"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=0.0001, add_prev_output_tokens=False, arch='roberta_large', attention_dropout=0.1, best_checkpoint_metric='accuracy', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='train-bin/', dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=True, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=4, fp16_scale_tolerance=0.0, fp16_scale_window=128, init_token=0, keep_interval_updates=-1, keep_last_epochs=-1, log_format=None, log_interval=1000, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_positions=512, max_sentences=2, max_sentences_valid=2, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_shuffle=False, num_classes=2, num_workers=1, optimizer='adam', optimizer_overrides='{}', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, regression_target=False, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='model.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, save_predictions=None, seed=1, sentence_avg=False, separator_token=2, skip_invalid_size_inputs_valid_test=False, task='sentence_prediction', tensorboard_logdir='', threshold_loss_scale=1.0, tokenizer=None, total_num_update=10000, train_subset='train', truncate_sequence=True, update_freq=[16], use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=50, weight_decay=0.1)\n",
            "| [input] dictionary: 50265 types\n",
            "| [label] dictionary: 9 types\n",
            "| loaded 10000 examples from: train-bin/input0/valid\n",
            "| loaded 10000 examples from: train-bin/label/valid\n",
            "| Loaded valid with #samples: 10000\n",
            "RobertaModel(\n",
            "  (decoder): RobertaEncoder(\n",
            "    (sentence_encoder): TransformerSentenceEncoder(\n",
            "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
            "      (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (6): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (7): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (8): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (9): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (10): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (11): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (12): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (13): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (14): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (15): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (16): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (17): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (18): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (19): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (20): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (21): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (22): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (23): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (emb_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (lm_head): RobertaLMHead(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (classification_heads): ModuleDict(\n",
            "    (sentence_classification_head): RobertaClassificationHead(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "| model roberta_large, criterion SentencePredictionCriterion\n",
            "| num. model params: 356462683 (num. trained: 356462683)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = 4400 and max sentences per GPU = 2\n",
            "WARNING: deleting classification head (mnli) from checkpoint not present in current model: classification_heads.mnli.dense.weight\n",
            "WARNING: deleting classification head (mnli) from checkpoint not present in current model: classification_heads.mnli.dense.bias\n",
            "WARNING: deleting classification head (mnli) from checkpoint not present in current model: classification_heads.mnli.out_proj.weight\n",
            "WARNING: deleting classification head (mnli) from checkpoint not present in current model: classification_heads.mnli.out_proj.bias\n",
            "Overwriting classification_heads.sentence_classification_head.dense.weight\n",
            "Overwriting classification_heads.sentence_classification_head.dense.bias\n",
            "Overwriting classification_heads.sentence_classification_head.out_proj.weight\n",
            "Overwriting classification_heads.sentence_classification_head.out_proj.bias\n",
            "| loaded checkpoint model.pt (epoch 0 @ 0 updates)\n",
            "| WARNING: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster\n",
            "| loading train data for epoch 0\n",
            "| loaded 60000 examples from: train-bin/input0/train\n",
            "| loaded 60000 examples from: train-bin/label/train\n",
            "| Loaded train with #samples: 60000\n",
            "| epoch 001:  72% 1344/1875 [46:51<17:26,  1.97s/it, loss=0.629, nll_loss=0.005, ppl=1, wps=1984, ups=0, wpb=4151.592, bsz=32.000, num_updates=1344, lr=8.6995e-06, gnorm=3.603, clip=0.000, oom=0.000, loss_scale=4096.000, wall=2812, train_wall=2753, accuracy=0.812942]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 001:  89% 1675/1875 [58:26<07:02,  2.11s/it, loss=0.624, nll_loss=0.005, ppl=1, wps=1984, ups=0, wpb=4155.130, bsz=32.000, num_updates=1674, lr=8.36784e-06, gnorm=3.311, clip=0.000, oom=0.000, loss_scale=8192.000, wall=3507, train_wall=3433, accuracy=0.813079]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 001:  97% 1827/1875 [1:03:47<01:44,  2.17s/it, loss=0.624, nll_loss=0.005, ppl=1, wps=1982, ups=0, wpb=4157.209, bsz=32.000, num_updates=1825, lr=8.21608e-06, gnorm=3.219, clip=0.000, oom=0.000, loss_scale=8192.000, wall=3828, train_wall=3747, accuracy=0.812671]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 001 | loss 0.623 | nll_loss 0.005 | ppl 1 | wps 1981 | ups 0 | wpb 4156.749 | bsz 32.000 | num_updates 1872 | lr 8.16884e-06 | gnorm 3.197 | clip 0.000 | oom 0.000 | loss_scale 4096.000 | wall 3928 | train_wall 3845 | accuracy 0.813084\n",
            "| epoch 001 | valid on 'valid' subset | loss 0.684 | nll_loss 0.006 | ppl 1 | num_updates 1872 | accuracy 0.7687\n",
            "tcmalloc: large alloc 1425858560 bytes == 0x9cef0000 @  0x7f0a6978bb6b 0x7f0a697ab379 0x7f0a12f07b4a 0x7f0a12f095fa 0x7f0a1523978a 0x7f0a1548230b 0x7f0a154c9b37 0x7f0a17489795 0x7f0a154c9b37 0x7f0a15232346 0x7f0a152340d6 0x7f0a15577bf3 0x7f0a1725ddb2 0x7f0a155c264a 0x7f0a5dc30fd9 0x7f0a5dd4aa01 0x50ac25 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245\n",
            "tcmalloc: large alloc 1425858560 bytes == 0xf1ebe000 @  0x7f0a6978bb6b 0x7f0a697ab379 0x7f0a12f07b4a 0x7f0a12f095fa 0x7f0a1523978a 0x7f0a1548230b 0x7f0a154c9b37 0x7f0a17489795 0x7f0a154c9b37 0x7f0a15232346 0x7f0a152340d6 0x7f0a15577bf3 0x7f0a1725ddb2 0x7f0a155c264a 0x7f0a5dc30fd9 0x7f0a5dd4aa01 0x50ac25 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245\n",
            "| saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 1872 updates) (writing took 264.6860291957855 seconds)\n",
            "| epoch 002:  12% 225/1875 [07:48<59:26,  2.16s/it, loss=0.601, nll_loss=0.005, ppl=1, wps=1985, ups=0, wpb=4134.178, bsz=32.000, num_updates=2097, lr=7.94271e-06, gnorm=2.097, clip=0.000, oom=0.000, loss_scale=16384.000, wall=4868, train_wall=4303, accuracy=0.8175]  | WARNING: overflow detected, setting loss scale to: 8192.0\n",
            "| epoch 002:  15% 288/1875 [09:59<53:13,  2.01s/it, loss=0.600, nll_loss=0.005, ppl=1, wps=1979, ups=0, wpb=4132.003, bsz=32.000, num_updates=2159, lr=7.8804e-06, gnorm=2.144, clip=0.000, oom=0.000, loss_scale=8192.000, wall=4998, train_wall=4431, accuracy=0.818706] | WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 002:  25% 472/1875 [16:24<49:47,  2.13s/it, loss=0.594, nll_loss=0.005, ppl=1, wps=1977, ups=0, wpb=4141.611, bsz=32.000, num_updates=2342, lr=7.69648e-06, gnorm=2.143, clip=0.000, oom=0.000, loss_scale=8192.000, wall=5383, train_wall=4808, accuracy=0.822872]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 002:  37% 693/1875 [24:07<38:34,  1.96s/it, loss=0.596, nll_loss=0.005, ppl=1, wps=1978, ups=0, wpb=4150.006, bsz=32.000, num_updates=2562, lr=7.47538e-06, gnorm=2.144, clip=0.000, oom=0.000, loss_scale=8192.000, wall=5847, train_wall=5262, accuracy=0.822917]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 002:  44% 823/1875 [28:38<37:16,  2.13s/it, loss=0.597, nll_loss=0.005, ppl=1, wps=1977, ups=0, wpb=4150.024, bsz=32.000, num_updates=2691, lr=7.34573e-06, gnorm=2.149, clip=0.000, oom=0.000, loss_scale=8192.000, wall=6118, train_wall=5527, accuracy=0.822192]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 002:  54% 1019/1875 [35:32<30:55,  2.17s/it, loss=0.597, nll_loss=0.005, ppl=1, wps=1978, ups=0, wpb=4159.808, bsz=32.000, num_updates=2886, lr=7.14975e-06, gnorm=2.152, clip=0.000, oom=0.000, loss_scale=8192.000, wall=6532, train_wall=5932, accuracy=0.820913]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 002:  60% 1117/1875 [38:56<25:16,  2.00s/it, loss=0.599, nll_loss=0.005, ppl=1, wps=1977, ups=0, wpb=4157.207, bsz=32.000, num_updates=2983, lr=7.05226e-06, gnorm=2.165, clip=0.000, oom=0.000, loss_scale=4096.000, wall=6735, train_wall=6132, accuracy=0.819757]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 002:  70% 1307/1875 [45:38<19:46,  2.09s/it, loss=0.599, nll_loss=0.005, ppl=1, wps=1974, ups=0, wpb=4158.190, bsz=32.000, num_updates=3172, lr=6.86231e-06, gnorm=2.198, clip=0.000, oom=0.000, loss_scale=4096.000, wall=7137, train_wall=6525, accuracy=0.820312]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 002:  91% 1697/1875 [59:16<06:27,  2.18s/it, loss=0.599, nll_loss=0.005, ppl=1, wps=1975, ups=0, wpb=4157.387, bsz=32.000, num_updates=3561, lr=6.47136e-06, gnorm=2.188, clip=0.000, oom=0.000, loss_scale=16384.000, wall=7955, train_wall=7325, accuracy=0.819605]| WARNING: overflow detected, setting loss scale to: 8192.0\n",
            "| epoch 002:  95% 1785/1875 [1:02:21<03:00,  2.01s/it, loss=0.600, nll_loss=0.005, ppl=1, wps=1973, ups=0, wpb=4156.171, bsz=32.000, num_updates=3648, lr=6.38392e-06, gnorm=2.193, clip=0.000, oom=0.000, loss_scale=8192.000, wall=8140, train_wall=7506, accuracy=0.819591]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 002 | loss 0.599 | nll_loss 0.005 | ppl 1 | wps 1972 | ups 0 | wpb 4156.468 | bsz 32.000 | num_updates 3737 | lr 6.29447e-06 | gnorm 2.189 | clip 0.000 | oom 0.000 | loss_scale 4096.000 | wall 8329 | train_wall 7691 | accuracy 0.819822\n",
            "| epoch 002 | valid on 'valid' subset | loss 0.673 | nll_loss 0.006 | ppl 1 | num_updates 3737 | best_accuracy 0.769 | accuracy 0.769\n",
            "tcmalloc: large alloc 1425858560 bytes == 0x9cef0000 @  0x7f0a6978bb6b 0x7f0a697ab379 0x7f0a12f07b4a 0x7f0a12f095fa 0x7f0a1523978a 0x7f0a1548230b 0x7f0a154c9b37 0x7f0a17489795 0x7f0a154c9b37 0x7f0a15232346 0x7f0a152340d6 0x7f0a15577bf3 0x7f0a1725ddb2 0x7f0a155c264a 0x7f0a5dc30fd9 0x7f0a5dd4aa01 0x50ac25 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245\n",
            "| saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 3737 updates) (writing took 259.277884721756 seconds)\n",
            "| epoch 003:   6% 113/1875 [03:56<58:28,  1.99s/it, loss=0.593, nll_loss=0.005, ppl=1, wps=1982, ups=0, wpb=4151.265, bsz=32.000, num_updates=3850, lr=6.1809e-06, gnorm=2.256, clip=0.000, oom=0.000, loss_scale=8192.000, wall=9034, train_wall=7922, accuracy=0.823562] | WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 003:  21% 387/1875 [13:35<50:21,  2.03s/it, loss=0.604, nll_loss=0.005, ppl=1, wps=1977, ups=0, wpb=4176.938, bsz=32.000, num_updates=4123, lr=5.90653e-06, gnorm=2.247, clip=0.000, oom=0.000, loss_scale=16384.000, wall=9612, train_wall=8489, accuracy=0.821648]| WARNING: overflow detected, setting loss scale to: 8192.0\n",
            "| epoch 003:  23% 435/1875 [15:16<49:50,  2.08s/it, loss=0.605, nll_loss=0.005, ppl=1, wps=1973, ups=0, wpb=4176.259, bsz=32.000, num_updates=4170, lr=5.8593e-06, gnorm=2.262, clip=0.000, oom=0.000, loss_scale=8192.000, wall=9713, train_wall=8588, accuracy=0.821161]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 003:  29% 545/1875 [19:07<46:58,  2.12s/it, loss=0.603, nll_loss=0.005, ppl=1, wps=1971, ups=0, wpb=4173.566, bsz=32.000, num_updates=4279, lr=5.74975e-06, gnorm=2.293, clip=0.000, oom=0.000, loss_scale=4096.000, wall=9945, train_wall=8814, accuracy=0.820687]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 003:  43% 803/1875 [28:07<38:31,  2.16s/it, loss=0.601, nll_loss=0.005, ppl=1, wps=1973, ups=0, wpb=4166.477, bsz=32.000, num_updates=4536, lr=5.49146e-06, gnorm=2.349, clip=0.000, oom=0.000, loss_scale=8192.000, wall=10484, train_wall=9342, accuracy=0.820361]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 003:  47% 878/1875 [30:47<35:04,  2.11s/it, loss=0.603, nll_loss=0.005, ppl=1, wps=1971, ups=0, wpb=4170.670, bsz=32.000, num_updates=4610, lr=5.41709e-06, gnorm=2.364, clip=0.000, oom=0.000, loss_scale=4096.000, wall=10644, train_wall=9499, accuracy=0.819086]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 003:  67% 1256/1875 [43:58<20:45,  2.01s/it, loss=0.596, nll_loss=0.005, ppl=1, wps=1972, ups=0, wpb=4162.366, bsz=32.000, num_updates=4987, lr=5.03819e-06, gnorm=2.402, clip=0.000, oom=0.000, loss_scale=8192.000, wall=11436, train_wall=10274, accuracy=0.82125]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 003:  81% 1513/1875 [52:59<12:31,  2.08s/it, loss=0.596, nll_loss=0.005, ppl=1, wps=1973, ups=0, wpb=4164.904, bsz=32.000, num_updates=5243, lr=4.7809e-06, gnorm=2.446, clip=0.000, oom=0.000, loss_scale=16384.000, wall=11976, train_wall=10803, accuracy=0.821651]| WARNING: overflow detected, setting loss scale to: 8192.0\n",
            "| epoch 003:  81% 1527/1875 [53:28<12:07,  2.09s/it, loss=0.595, nll_loss=0.005, ppl=1, wps=1972, ups=0, wpb=4165.016, bsz=32.000, num_updates=5256, lr=4.76784e-06, gnorm=2.446, clip=0.000, oom=0.000, loss_scale=8192.000, wall=12005, train_wall=10831, accuracy=0.821963]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 003:  88% 1659/1875 [58:03<07:30,  2.09s/it, loss=0.595, nll_loss=0.005, ppl=1, wps=1972, ups=0, wpb=4164.328, bsz=32.000, num_updates=5387, lr=4.63618e-06, gnorm=2.463, clip=0.000, oom=0.000, loss_scale=8192.000, wall=12281, train_wall=11101, accuracy=0.82161] | WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 003:  96% 1794/1875 [1:02:44<02:56,  2.18s/it, loss=0.594, nll_loss=0.005, ppl=1, wps=1972, ups=0, wpb=4160.254, bsz=32.000, num_updates=5521, lr=4.50151e-06, gnorm=2.492, clip=0.000, oom=0.000, loss_scale=8192.000, wall=12561, train_wall=11375, accuracy=0.821574]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 003:  97% 1827/1875 [1:03:52<01:44,  2.18s/it, loss=0.594, nll_loss=0.005, ppl=1, wps=1970, ups=0, wpb=4157.812, bsz=32.000, num_updates=5553, lr=4.46935e-06, gnorm=2.505, clip=0.000, oom=0.000, loss_scale=4096.000, wall=12629, train_wall=11442, accuracy=0.821792]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 003 | loss 0.594 | nll_loss 0.005 | ppl 1 | wps 1970 | ups 0 | wpb 4156.215 | bsz 32.000 | num_updates 5600 | lr 4.42211e-06 | gnorm 2.515 | clip 0.000 | oom 0.000 | loss_scale 2048.000 | wall 12728 | train_wall 11538 | accuracy 0.822044\n",
            "| epoch 003 | valid on 'valid' subset | loss 0.662 | nll_loss 0.006 | ppl 1 | num_updates 5600 | best_accuracy 0.7966 | accuracy 0.7966\n",
            "| saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 5600 updates) (writing took 259.7966012954712 seconds)\n",
            "| epoch 004:  11% 209/1875 [07:16<58:40,  2.11s/it, loss=0.577, nll_loss=0.004, ppl=1, wps=1976, ups=0, wpb=4123.976, bsz=32.000, num_updates=5809, lr=4.21206e-06, gnorm=3.129, clip=0.000, oom=0.000, loss_scale=8192.000, wall=13632, train_wall=11965, accuracy=0.830742]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  22% 412/1875 [14:24<51:09,  2.10s/it, loss=0.590, nll_loss=0.005, ppl=1, wps=1976, ups=0, wpb=4154.861, bsz=32.000, num_updates=6011, lr=4.00905e-06, gnorm=2.981, clip=0.000, oom=0.000, loss_scale=8192.000, wall=14060, train_wall=12383, accuracy=0.824589]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  29% 546/1875 [19:06<45:31,  2.05s/it, loss=0.593, nll_loss=0.005, ppl=1, wps=1970, ups=0, wpb=4151.673, bsz=32.000, num_updates=6144, lr=3.87538e-06, gnorm=2.952, clip=0.000, oom=0.000, loss_scale=8192.000, wall=14343, train_wall=12660, accuracy=0.823012]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  38% 705/1875 [24:40<39:53,  2.05s/it, loss=0.594, nll_loss=0.005, ppl=1, wps=1968, ups=0, wpb=4150.306, bsz=32.000, num_updates=6302, lr=3.71658e-06, gnorm=2.967, clip=0.000, oom=0.000, loss_scale=8192.000, wall=14677, train_wall=12986, accuracy=0.822961]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  46% 863/1875 [30:12<34:09,  2.02s/it, loss=0.589, nll_loss=0.005, ppl=1, wps=1968, ups=0, wpb=4151.236, bsz=32.000, num_updates=6459, lr=3.55879e-06, gnorm=2.982, clip=0.000, oom=0.000, loss_scale=8192.000, wall=15008, train_wall=13311, accuracy=0.825997]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  54% 1016/1875 [35:31<29:25,  2.06s/it, loss=0.593, nll_loss=0.005, ppl=1, wps=1966, ups=0, wpb=4145.609, bsz=32.000, num_updates=6611, lr=3.40603e-06, gnorm=2.976, clip=0.000, oom=0.000, loss_scale=8192.000, wall=15328, train_wall=13623, accuracy=0.824339]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  66% 1240/1875 [43:25<22:16,  2.10s/it, loss=0.591, nll_loss=0.005, ppl=1, wps=1968, ups=0, wpb=4155.941, bsz=32.000, num_updates=6834, lr=3.18191e-06, gnorm=2.972, clip=0.000, oom=0.000, loss_scale=8192.000, wall=15802, train_wall=14087, accuracy=0.824706]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  73% 1371/1875 [48:00<18:04,  2.15s/it, loss=0.590, nll_loss=0.005, ppl=1, wps=1968, ups=0, wpb=4156.275, bsz=32.000, num_updates=6964, lr=3.05126e-06, gnorm=3.000, clip=0.000, oom=0.000, loss_scale=8192.000, wall=16077, train_wall=14356, accuracy=0.825238]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  80% 1506/1875 [52:44<12:23,  2.02s/it, loss=0.588, nll_loss=0.005, ppl=1, wps=1968, ups=0, wpb=4156.557, bsz=32.000, num_updates=7098, lr=2.91658e-06, gnorm=3.007, clip=0.000, oom=0.000, loss_scale=8192.000, wall=16360, train_wall=14633, accuracy=0.825747]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 004:  84% 1580/1875 [55:21<10:44,  2.18s/it, loss=0.588, nll_loss=0.005, ppl=1, wps=1967, ups=0, wpb=4159.262, bsz=32.000, num_updates=7171, lr=2.84322e-06, gnorm=3.007, clip=0.000, oom=0.000, loss_scale=4096.000, wall=16518, train_wall=14787, accuracy=0.826026]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 004 | loss 0.586 | nll_loss 0.005 | ppl 1 | wps 1968 | ups 0 | wpb 4156.950 | bsz 32.000 | num_updates 7465 | lr 2.54774e-06 | gnorm 3.049 | clip 0.000 | oom 0.000 | loss_scale 8192.000 | wall 17135 | train_wall 15392 | accuracy 0.82681\n",
            "| epoch 004 | valid on 'valid' subset | loss 0.688 | nll_loss 0.006 | ppl 1 | num_updates 7465 | best_accuracy 0.7966 | accuracy 0.7845\n",
            "| saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 7465 updates) (writing took 164.4335196018219 seconds)\n",
            "| epoch 005:   0% 0/1875 [00:00<?, ?it/s]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 005:   8% 155/1875 [05:26<1:01:21,  2.14s/it, loss=0.579, nll_loss=0.004, ppl=1, wps=915, ups=0, wpb=4153.987, bsz=32.000, num_updates=7619, lr=2.39296e-06, gnorm=3.159, clip=0.000, oom=0.000, loss_scale=8192.000, wall=17835, train_wall=15711, accuracy=0.826096]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 005:  16% 298/1875 [10:26<53:40,  2.04s/it, loss=0.563, nll_loss=0.004, ppl=1, wps=1227, ups=0, wpb=4141.507, bsz=32.000, num_updates=7761, lr=2.25025e-06, gnorm=3.365, clip=0.000, oom=0.000, loss_scale=8192.000, wall=18135, train_wall=16005, accuracy=0.833509]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 005:  23% 431/1875 [15:06<47:47,  1.99s/it, loss=0.569, nll_loss=0.004, ppl=1, wps=1387, ups=0, wpb=4146.086, bsz=32.000, num_updates=7893, lr=2.11759e-06, gnorm=3.418, clip=0.000, oom=0.000, loss_scale=8192.000, wall=18415, train_wall=16278, accuracy=0.831557]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 005:  23% 438/1875 [15:22<51:57,  2.17s/it, loss=0.570, nll_loss=0.004, ppl=1, wps=1390, ups=0, wpb=4147.682, bsz=32.000, num_updates=7899, lr=2.11156e-06, gnorm=3.419, clip=0.000, oom=0.000, loss_scale=4096.000, wall=18430, train_wall=16293, accuracy=0.831437]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 005:  33% 621/1875 [21:44<44:43,  2.14s/it, loss=0.574, nll_loss=0.004, ppl=1, wps=1523, ups=0, wpb=4146.567, bsz=32.000, num_updates=8081, lr=1.92864e-06, gnorm=3.470, clip=0.000, oom=0.000, loss_scale=4096.000, wall=18813, train_wall=16668, accuracy=0.829292]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 005:  47% 880/1875 [30:48<35:11,  2.12s/it, loss=0.576, nll_loss=0.004, ppl=1, wps=1631, ups=0, wpb=4144.721, bsz=32.000, num_updates=8339, lr=1.66935e-06, gnorm=3.596, clip=0.000, oom=0.000, loss_scale=8192.000, wall=19357, train_wall=17200, accuracy=0.828018]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 005:  51% 964/1875 [33:42<31:35,  2.08s/it, loss=0.577, nll_loss=0.004, ppl=1, wps=1654, ups=0, wpb=4140.985, bsz=32.000, num_updates=8422, lr=1.58593e-06, gnorm=3.629, clip=0.000, oom=0.000, loss_scale=4096.000, wall=19531, train_wall=17370, accuracy=0.828337]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 005:  60% 1117/1875 [39:05<27:06,  2.15s/it, loss=0.575, nll_loss=0.004, ppl=1, wps=1692, ups=0, wpb=4147.563, bsz=32.000, num_updates=8574, lr=1.43317e-06, gnorm=3.686, clip=0.000, oom=0.000, loss_scale=4096.000, wall=19853, train_wall=17685, accuracy=0.828872]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 005:  75% 1402/1875 [49:09<17:08,  2.18s/it, loss=0.577, nll_loss=0.004, ppl=1, wps=1744, ups=0, wpb=4159.837, bsz=32.000, num_updates=8858, lr=1.14774e-06, gnorm=3.709, clip=0.000, oom=0.000, loss_scale=8192.000, wall=20458, train_wall=18276, accuracy=0.829168]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 005:  82% 1545/1875 [54:08<11:33,  2.10s/it, loss=0.578, nll_loss=0.004, ppl=1, wps=1762, ups=0, wpb=4157.012, bsz=32.000, num_updates=9000, lr=1.00503e-06, gnorm=3.700, clip=0.000, oom=0.000, loss_scale=8192.000, wall=20756, train_wall=18569, accuracy=0.828868]| WARNING: overflow detected, setting loss scale to: 4096.0\n",
            "| epoch 005:  86% 1615/1875 [56:35<09:21,  2.16s/it, loss=0.578, nll_loss=0.004, ppl=1, wps=1769, ups=0, wpb=4156.470, bsz=32.000, num_updates=9069, lr=9.35678e-07, gnorm=3.696, clip=0.000, oom=0.000, loss_scale=4096.000, wall=20904, train_wall=18713, accuracy=0.829099]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 005:  96% 1804/1875 [1:03:09<02:23,  2.01s/it, loss=0.578, nll_loss=0.004, ppl=1, wps=1789, ups=0, wpb=4155.142, bsz=32.000, num_updates=9257, lr=7.46734e-07, gnorm=3.699, clip=0.000, oom=0.000, loss_scale=4096.000, wall=21298, train_wall=19098, accuracy=0.829241]| WARNING: overflow detected, setting loss scale to: 2048.0\n",
            "| epoch 005 | loss 0.577 | nll_loss 0.004 | ppl 1 | wps 1794 | ups 0 | wpb 4156.324 | bsz 32.000 | num_updates 9327 | lr 6.76382e-07 | gnorm 3.706 | clip 0.000 | oom 0.000 | loss_scale 2048.000 | wall 21448 | train_wall 19245 | accuracy 0.829602\n",
            "| epoch 005 | valid on 'valid' subset | loss 0.678 | nll_loss 0.006 | ppl 1 | num_updates 9327 | best_accuracy 0.7966 | accuracy 0.7893\n",
            "| saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 9327 updates) (writing took 164.39565467834473 seconds)\n",
            "| done training in 21823.0 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}